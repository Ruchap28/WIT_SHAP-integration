# ðŸ” Enhancing the What-If Tool (WIT) with SHAP-Based Explainability

This project integrates **SHAP (SHapley Additive exPlanations)** into the **What-If Tool (WIT)** framework with firebase authentication enabling a more interpretable and transparent understanding of machine learning model predictions â€” especially for tabular data.

It allows users to:

- Upload custom datasets (with numerical and categorical features)
- Train an XGBoost model
- Visualize global and local feature contributions using SHAP plots
- Understand and explain individual predictions interactively
- Export insights for research or decision-making purposes

## ðŸš€ Features

- âœ… Upload a CSV dataset
- âœ… Automatic handling of numerical features
- âœ… Train XGBoost model internally
- âœ… SHAP plots:
  - Global Feature Importance
  - Beeswarm Plot
  - Waterfall Plot for specific predictions
- âœ… Interactive UI with **Streamlit**
- âœ… Detailed prediction breakdown (textual + visual)
- âœ… Graceful error handling and user feedback

---

## ðŸ§ª Demo

| ðŸ“Š Global Importance -> Displays feature importance across the dataset |
| ðŸ Beeswarm Plot -> Visualizes SHAP values per instance and feature |
| ðŸ’§ Waterfall Plot -> Explains single predictions |
| ðŸ“ƒ Textual Explanation -> Breaks down feature-wise SHAP values |

ðŸ“Ž **Sample Output (PDF)**: See the `WIT_Output.pdf` included in this repository.

---
